{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7 - Using NumPy \n",
    "by Kaan Kabalak @ witfuldata.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Amazing World of Data Science Libraries\n",
    "\n",
    "All right, now we are talking! This part is our first step into the world of data science.\n",
    "\n",
    "NumPy (short for Numeric Python) is one of the most popular data science libraries. What are the others? Let's see:\n",
    "\n",
    "* Matplotlib (for data visualization)\n",
    "* Pandas (for data manipulation and analysis)\n",
    "* SciPy (for statistical and scientific computations, short for Scientific Python)\n",
    "* Scikit-learn (ready-to-use algorithms for data preparation and machine learning)\n",
    "\n",
    "Why did we start with NumPy?\n",
    "\n",
    "Because most of the functionalities of these libraries are built or structured on NumPy.\n",
    "\n",
    "In this part, we are going to go through some of the core NumPy functionalities that are often used by data science libraries. We are also going to take a first look at the statistical concept of descriptive statistics through NumPy's statistical functions. \n",
    "\n",
    "Please note that, like previous parts of this tutorial, this part will focus only on the necessary things about NumPy which you need to understand to understand how other libraries use its structure. This is not a tutorial which aims to teach every aspect of NumPy. \n",
    "\n",
    "Let's see what NumPy has to offer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing & Importing Libraries\n",
    "\n",
    "I am not going to go over how to install Python libraries. There are many tutorials about it. It is something simple that takes only a few minutes at max and if you installed Anaconda as I suggested earlier, you do not have to install NumPy separately. Anaconda already comes with an installation of NumPy.\n",
    "\n",
    "\n",
    "After you install a library you can import it with the import keyword. Here we will import numpy as np:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Arrays\n",
    "\n",
    "NumPy arrays are list-like collection variables that can hold single or multiple values. They look like Python's lists but are different in various ways. We will take a look at some of those differences but first let's see how these arrays are defined. \n",
    "\n",
    "A NumPy array is defined by using the array method of numpy and passing a list as an argument to this method. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array = np.array([17, 54, 62, 75, 86])\n",
    "type (a_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important aspect of NumPy arrays is dimension. \n",
    "\n",
    "One dimensional arrays are defined by passing only 1 list to the array method as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One dimensional array\n",
    "oned_array = np.array ([1, 2, 3, 4])\n",
    "oned_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move onto defining multi-dimensional arrays, let's take a look at the attributes of NumPy arrays. The attributes can be used like methods but without the parantheses ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension\n",
    "oned_array.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape (the number of rows, the number of columns)\n",
    "oned_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size (The total number of elements)\n",
    "oned_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define two dimensional arrays by passing a list of lists into the array method as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6, 8],\n",
       "       [1, 3, 5, 7],\n",
       "       [9, 5, 7, 3]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two-dimensional array\n",
    "twod_array = np.array(\n",
    "    [\n",
    "     [2, 4, 6, 8],\n",
    "     [1, 3, 5, 7], \n",
    "     [9, 5, 7, 3]\n",
    "     ]\n",
    "    )\n",
    "twod_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension\n",
    "twod_array.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape (the number of rows, the number of columns)\n",
    "twod_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size\n",
    "twod_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like two dimensional arrays, we can also define three dimensional arrays with a list of list of lists (try to read it fast :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]],\n",
       "\n",
       "       [[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]],\n",
       "\n",
       "       [[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threed_array = np.array([[[0, 1, 2, 3],\n",
    "                           [4, 5, 6, 7]],\n",
    "\n",
    "                          [[0, 1, 2, 3],\n",
    "                           [4, 5, 6, 7]],\n",
    "\n",
    "                          [[0 ,1 ,2, 3],\n",
    "                           [4, 5, 6, 7]]])\n",
    "threed_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the rows and columns are grouped together in 3 groups. There are 2 rows and 4 columns in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimension\n",
    "threed_array.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape\n",
    "threed_array.shape # 3 groups, 2 rows and 4 columns in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size\n",
    "threed_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping arrays\n",
    "\n",
    "We can also reshape arrays. The size of the reshaped array has to be the same as the size of the original array. In other words, the total number of elements must be the same in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6, 8],\n",
       "       [1, 3, 5, 7],\n",
       "       [9, 5, 7, 3]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twod_array = np.array([[2, 4, 6, 8],[1, 3, 5, 7], [9, 5, 7, 3]]) # Array with 3 rows and 4 columns\n",
    "twod_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 4, 6],\n",
       "       [8, 1, 3],\n",
       "       [5, 7, 9],\n",
       "       [5, 7, 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_two = twod_array.reshape(4, 3) # Reshape into 4 rows and 3 columns\n",
    "res_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7],\n",
       "        [0, 1, 2, 3]],\n",
       "\n",
       "       [[4, 5, 6, 7],\n",
       "        [0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_three = threed_array.reshape(2, 3, 4) # Reshape into 2 groups, 3 rows and 4 columns in each group\n",
    "res_three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Array Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define arrays in a very practical manner without writing values manually, using the np.arange function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 10, 20, 30, 40])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use np.arange to define an array with values between the range of 0-50, increasing by 10 at every step\n",
    "rn_array = np.arange(0,50,10) # Start from 0, finish before 50, add 10 at every step\n",
    "rn_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15,  30,  45,  60,  75,  90, 105, 120])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start from 15, finish before 135, add 15 at every step\n",
    "rntwo_array = np.arange(15,135,15)\n",
    "rntwo_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Operations (Broadcasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the point where NumPy arrays behave in a very different way when compared to Python lists. When you add two lists together, Python will just append one of the lists to the other. It won't return the sum of the elements. Also, there are many arithmetic operations that you cannot do with Python lists without writing loops. Let's see how Python lists can be limited for arithmetic operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding lists together\n",
    "b_list = [1, 2, 3, 4]\n",
    "\n",
    "c_list = [5, 6, 7, 8]\n",
    "\n",
    "b_list + c_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add the elements of c_list to b_list, we would have to write a loop (which is time consuming and inefficient in computational terms):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 10, 12]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an empty list\n",
    "sum_list = [] \n",
    "# Iterate over enumerated b_list\n",
    "for n,x in enumerate(b_list):\n",
    "    # Iterate over enumerated c_list\n",
    "    for m, y in enumerate (c_list):\n",
    "        # Only add elements with matching index numbers (to avoid adding every element of c_list to every element b_list in iteration)\n",
    "        if n == m:\n",
    "            sum_list.append (y + x)\n",
    "        else:\n",
    "            pass\n",
    "sum_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike Python's lists, NumPy arrays are designed for the ease of mathmetical operations. The array operations are distributed to each element of the arrays. This is called broadcasting. NumPy broadcasts the elements of an array to the corresponding ones in the other array. To understand this better, let's repeat the operation in the code block above, but this time with NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8, 10, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an array to another\n",
    "b_vector = np.array ([1, 2, 3, 4])\n",
    "\n",
    "c_vector = np.array ([5, 6, 7, 8])\n",
    "b_vector + c_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,  26,  42,  60],\n",
       "       [ 55, 102, 126, 152]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply arrays\n",
    "b_mdarr = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8]])\n",
    "\n",
    "c_mdarr = np.array ([[12, 13, 14, 15],\n",
    "                     [11, 17, 18, 19]])\n",
    "\n",
    "b_mdarr * c_mdarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 3. , 3.5, 4. ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use array variables in operations\n",
    "fr_arr = np.array([5, 6, 7, 8])\n",
    "sn_arr = np.array(fr_arr / 2)\n",
    "sn_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistical Functions\n",
    "\n",
    "Descriptive Statistics are statistical measures that help us understand how our data is structured.\n",
    "We will get into descriptive statistics in future parts, but it would be beneficial to take a look at some NumPy functions that help us describe our data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max, Min and Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have the max and min functions which return the maximum and minimum values of an array. The ptp function can be used to return the range (max-min) of an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr = np.array([3, 10, 20, 35, 40, 58, 67 ,74, 87 , 96, 120])\n",
    "\n",
    "x_arr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ptp (x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles\n",
    "\n",
    "What are percentiles? The percentiles basically represent the values that are larger than n percent of the total values. Here n refers to the percentile. For example, when we check the 25th percentile, we are actually check the value that is larger than the 25 percent of all values. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "27.5\n",
      "58.0\n",
      "80.5\n",
      "120.0\n"
     ]
    }
   ],
   "source": [
    "x_arr = np.array([3, 10, 20, 35, 40, 58, 67 ,74, 87 , 96, 120])\n",
    "\n",
    "print (np.percentile (x_arr, 10)) # Value that is (or would be) larger than the 10 percent of all values\n",
    "print (np.percentile (x_arr, 25)) # Value that is (or would be) larger than the 25 percent of all values\n",
    "print (np.percentile (x_arr, 50)) # Value that is (or would be) larger than the 50 percent of all values\n",
    "print (np.percentile (x_arr, 75)) # Value that is (or would be) larger than the 75 percent of all values\n",
    "print (np.percentile (x_arr, 100))# Value that is (or would be) larger than the 100 percent of all values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean & Median\n",
    "\n",
    "We can also take a look at measures like mean and median. The explanation of these statistical measures are as follows:\n",
    "\n",
    "* <strong> Mean </strong> : The arithmetic average of the array. Calculated by dividing the sum of all elements by the number of all elements. \n",
    "\n",
    "* <strong> Median </strong> : The middle value. In other words, the value that is larger than % 50 of all values. If there are two values in the middle, then their average is taken as the median. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.array([3, 10, 20, 35, 40, 58, 67 ,74, 87 , 96, 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.45454545454545"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean\n",
    "np.mean (x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's manually calculate the mean of x_arr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.45454545454545"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sum of all values\n",
    "sum_val = np.sum(x_arr)\n",
    "\n",
    "# The number of all elements (array length)\n",
    "arr_num = len(x_arr)\n",
    "\n",
    "# Divide\n",
    "arr_mean = sum_val / arr_num\n",
    "arr_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the result is the same as the one produced by the np.mean( ) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the median of our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Median\n",
    "np.median (x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing about mean and median is how they relate to outliers. Outliers can be understood as exteremly low or high values in your data (in this case, the data in your array). Mean is sensitive to outliers. This means that if you have very high or low value in your data, this can distort the mean and give you the wrong idea about the situation. \n",
    "\n",
    "Median, on the other hand, is not so sensitive to outliers. \n",
    "\n",
    "If you have outliers in your data, it is better to use the median. \n",
    "\n",
    "Let's see an example to understand better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the array is 38.1,\n",
      "The median of the array is 40.5\n"
     ]
    }
   ],
   "source": [
    "# An array without an outlier\n",
    "nrm_array = np.array([10, 15, 20, 30, 38, 43, 45, 50, 60, 70])\n",
    "print (\"The mean of the array is {},\\nThe median of the array is {}\".format(np.mean(nrm_array),np.median(nrm_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the array is 115.54545454545455,\n",
      "The median of the array is 43.0\n"
     ]
    }
   ],
   "source": [
    "# An array with an outlier (890)\n",
    "nrm_array = np.array([10, 15, 20, 30, 38, 43, 45, 50, 60, 70, 890])\n",
    "print (\"The mean of the array is {},\\nThe median of the array is {}\".format(np.mean(nrm_array),np.median(nrm_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the mean changed drastically while the median stayed mostly the same. This makes median much more reliable when outlier values are present. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance and Standart Deviation\n",
    "\n",
    "* <strong> Variance </strong> : The sum of the squared distances of each element to the mean. It is simply performed by substracting the mean value of the array from each element, taking the square of the result and then taking the sum of all results. After that, you divide this result by the length of your array.\n",
    "\n",
    "The square of the differences (the result of substraction) is taken to make negative values neutral. Think of it like this, if an element has a value smaller than the mean, the result of the substraction will be negative. This will cause some results to be negative while the result of the substraction with elements larger than the mean are positive. When you add them up, the smaller values' distances to the mean will cancel most of the larger values' distances to the mean. In the end, you will have the wrong idea about the distances of elements to the mean. To prevent all this, you take the square of the result of the substraction (element value - mean value), because of the fact that the square of a negative value is always positive. \n",
    "\n",
    "Variance shows how much our data varies within itself. Why is this important? \n",
    "\n",
    "Because it tells you how well a randomly picked value will represent the mean of your data. Low variance means that there is higher probability that a randomly picked value will represent the mean of your data. \n",
    "\n",
    "* <strong> Standard Deviation </strong> : Standart deviation is the square root of variance. When we take the square of distances for variance we also cause the scale of the data points to be distorted. Standart deviation allows us to fix this by taking the square root. The usage of standart deviation for the description of data variance is more common than the usage of variance only by itself. This is due to the fact that the standart deviation is more in line with the unit of the data itsel whereas the unit of variance will be much larger than the unit of data itself. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274.611570247934"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arr = np.array([3, 10, 20, 35, 40, 58, 67 ,74, 87 , 96, 120])\n",
    "\n",
    "# Variance \n",
    "np.var (x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have some fun and see how variance can be calculated manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1274.611570247934"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The distances of values to the mean\n",
    "distances_x = x_arr - np.mean(x_arr)\n",
    "\n",
    "# The square of the distances (to make negative values neutral)\n",
    "distances_sq_x = distances_x ** 2\n",
    "\n",
    "# The sum of the squared distances\n",
    "sum_dsq_x = np.sum(distances_sq_x)\n",
    "\n",
    "# Divide the result by the number of elements\n",
    "arr_variance = sum_dsq_x/len(x_arr)\n",
    "arr_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value of x_arr is 120, but the variance we got here is 1274, more than 10 times larger when compared to 120! As I have explained earlier, this is the reason standard deviation is used more commonly than variance. Standard deviation is the square root of variance and is much closer to the unit of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.70170262393565"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard deviation\n",
    "arr_std = np.std(x_arr)\n",
    "arr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of the variation of the array is: 35.70170262393565\n",
      "The standard deviation of the array is: 35.70170262393565\n"
     ]
    }
   ],
   "source": [
    "print (\"The square root of the variation of the array is: {}\".format(np.sqrt(np.var(x_arr))))\n",
    "print (\"The standard deviation of the array is: {}\".format(np.std (x_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and Correlation\n",
    "\n",
    "<strong>Covariance</strong> helps us measure how two variables are related to each other. This is done by multiplying the distance of a variable (in this case x_arr) to its mean with the distance of another variable to its mean (in this case y_arr). After the multiplication, we divide the result by the total number of observations (elements) - 1 (the length of the arrays - 1). \n",
    "\n",
    "Why do we substract 1 from the number of observations? \n",
    "\n",
    "We will go through tutorials which focus more intensely on statistical topics. I will explain this in those parts because it can require a lot of space for a tutorial that was intended to get you started. For now, let's just say it is not crucial that you understand this. The more important thing is what covariance tells you about the relation between variables and how its the building block of correlation coefficients (which you will see just a few blocks below from here). If you understood that, don't worry much about the rest. You got the essence of it all fine. \n",
    "\n",
    "Note that covariance may have a negative value which indicates that there is a negative relation between variables (one decreases while other increases vice versa). You should also know that a covariance of a variable with itself is actually that variable's variance. In other terms, cov(x_arr) = var(x_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.array([3, 10, 20, 35, 40, 58, 67 ,74, 87 , 96, 120])\n",
    "y_arr = np.array([7, 13, 25, 38, 42, 59, 68, 79, 88, 98, 127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1402.07272727, 1407.62727273],\n",
       "       [1407.62727273, 1417.07272727]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov (x_arr,y_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows us the covariance of each variable with itself (which is the same thing as their variance) and their covariance with the other variable.\n",
    "\n",
    "The resulting array can be read like this:\n",
    "\n",
    "[cov(x_arr, x_arr), cov(x_arr, y_arr)\n",
    "\n",
    "cov(x_arr, y_arr), cov(y_arr, y_arr)\n",
    "]\n",
    "\n",
    "In this case this means that:\n",
    "\n",
    "* The covariance of x_arr with itself (its variance) is 1402.07272727 (indicated in top left)\n",
    "* The covariance between x_arr and y_arr is 1407.62727273 (indicated in top right and bottom left)\n",
    "* The covariance of y_arr with itself (its variance) is 1417.07272727 (indicated in bottom right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1407.6272727272728"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distance of x_arr to its mean\n",
    "x_dist = x_arr - np.mean(x_arr)\n",
    "\n",
    "# Distance of y_arr to its mean\n",
    "y_dist = y_arr - np.mean(y_arr)\n",
    "\n",
    "# Multiply the distances (take their product)\n",
    "multip_dist = x_dist * y_dist\n",
    "\n",
    "# Sum of the product of distances\n",
    "sum_mdist = np.sum(multip_dist)\n",
    "\n",
    "# Divide by number of elements - 1\n",
    "cov_manu_xy = sum_mdist / (len(x_arr) - 1)\n",
    "cov_manu_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make covariance more understandable we can use the np.corrcoef( ) function. This returns the <strong>Pearson Correlation Coefficient </strong>. Like covariance, it's basically a measure of how variable values are related to each other. It is, however, more readable than covariance which is much larger than the unit of the original data and does not come in a standardized form. \n",
    "\n",
    "For example, the covariance of x and y variables was 1407 which was more than 10 times larger than the maxium values of both arrays. It is hard to determine if this covariance of 1407 is large or small according to the range of values in the arrays. There is no standard. Because of this, it is not very possible to compare the covariance of x and y with (for example) the covariance of x and z.\n",
    "\n",
    "The Pearson Correlation Coefficient, on the other hand, is  standardized. Its value is always between -1 and 1.\n",
    "\n",
    "* -1 indicates a very strong negative correlation (one value decreases while the other increases)\n",
    "* 1 indicates a very strong positive correlation (one value increases while the other also increases)\n",
    "\n",
    "\n",
    "It is possible to compare the correlation coefficient between variables due to this standardized form. We can, for example, compare the correlation coefficient of x and y with the correlation coefficient of x and z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99863396],\n",
       "       [0.99863396, 1.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(x_arr,y_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting array can be read like this:\n",
    "\n",
    "[corrcoef(x_arr, x_arr), corrcoef(x_arr, y_arr)\n",
    "\n",
    "corrcoef(x_arr, y_arr), corrcoef(y_arr, y_arr)\n",
    "]\n",
    "\n",
    "The correlation coefficient of a variable with itself is always 1.\n",
    "\n",
    "Here, the correlation coefficient between x_arr and y_arr is 0.99 which indicates that there is a very strong positive correlation between the two because 0.99 is very close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pearson Correlation Coefficient is calculated by dividing the covariance of two variables (in this case x_arr and y_arr) by the product (multiplication) of the standart deviations of these two variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: I will not do a manual calculation for the corrcoef ( ) function, because NumPy carries out some extra computational processes when returning the result of the function. If we were to do these calculation by hand, the result could be a bit different. Do not worry, this does not mean that NumPy's result is not reliable. It just does a bit of editing to make things more readable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
